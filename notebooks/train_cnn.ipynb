{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31811e2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptim\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Para que el notebook vea la raíz del proyecto\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if ROOT_DIR not in sys.path:\n",
    "    sys.path.append(ROOT_DIR)\n",
    "\n",
    "print(\"ROOT_DIR:\", ROOT_DIR)\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bd3ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(ROOT_DIR, \"data\", \"iq_dataset.npz\")\n",
    "data = np.load(dataset_path)\n",
    "\n",
    "print(\"Claves en el archivo:\", data.files)\n",
    "\n",
    "X_train = data[\"X_train\"]   # (N_train, 2, Nsym)\n",
    "y_train = data[\"y_train\"]   # (N_train,)\n",
    "X_val   = data[\"X_val\"]\n",
    "y_val   = data[\"y_val\"]\n",
    "mods    = data[\"modulations\"]   # array de strings con nombres de clases\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_val  :\", X_val.shape)\n",
    "print(\"y_val  :\", y_val.shape)\n",
    "print(\"Clases:\", mods)\n",
    "num_classes = len(mods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b52f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IQModDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # X: numpy (N, 2, Nsym)\n",
    "        # y: numpy (N,)\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y).long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = IQModDataset(X_train, y_train)\n",
    "val_dataset   = IQModDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "len(train_dataset), len(val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddc5cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IQCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(IQCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(2, 16, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),      # 256 -> 128\n",
    "            nn.Conv1d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),      # 128 -> 64\n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),      # 64 -> 32\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),         # 64 * 32 features\n",
    "            nn.Linear(64 * 32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = IQCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc1d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            running_loss += loss.item() * X_batch.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1fff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15   # puedes subir/bajar esto\n",
    "best_val_acc = 0.0\n",
    "model_path = os.path.join(ROOT_DIR, \"data\", \"iq_cnn_model.pth\")\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d}: \"\n",
    "          f\"Train Loss={train_loss:.4f}, Train Acc={train_acc*100:.2f}% | \"\n",
    "          f\"Val Loss={val_loss:.4f}, Val Acc={val_acc*100:.2f}%\")\n",
    "\n",
    "    # Guardar el mejor modelo\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"classes\": mods,\n",
    "        }, model_path)\n",
    "        print(f\"  -> Modelo mejorado, guardado en {model_path}\")\n",
    "\n",
    "print(f\"Mejor exactitud en validación: {best_val_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59640154",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model_loaded = IQCNN(num_classes)\n",
    "model_loaded.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model_loaded.to(device)\n",
    "model_loaded.eval()\n",
    "\n",
    "class_names = [c for c in checkpoint[\"classes\"]]\n",
    "print(\"Clases:\", class_names)\n",
    "\n",
    "# Tomamos algunos ejemplos de validación\n",
    "X_batch, y_batch = next(iter(val_loader))\n",
    "X_batch = X_batch.to(device)\n",
    "y_batch = y_batch.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model_loaded(X_batch)\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    conf, preds = torch.max(probs, 1)\n",
    "\n",
    "for i in range(5):  # mostramos 5 ejemplos\n",
    "    true_label = class_names[y_batch[i].item()]\n",
    "    pred_label = class_names[preds[i].item()]\n",
    "    print(f\"Ejemplo {i}: true={true_label}, pred={pred_label}, conf={conf[i].item():.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
